"""
EagleEye FastAPI Application
REST API for inventory management analytics.
"""

from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta, date
from functools import lru_cache
import pandas as pd
import numpy as np
import sys
from pathlib import Path

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent))

from services.data_pipeline import DataPipeline
from models.production_forecaster import ProductionForecaster
from services.inventory_service import InventoryService


# ============================================================================
# Pydantic Models
# ============================================================================

class ForecastItem(BaseModel):
    date: str
    day_name: str
    predicted_demand: int
    lower_bound: int
    upper_bound: int


class ForecastResponse(BaseModel):
    forecast: List[ForecastItem]
    model_info: Dict[str, Any]
    generated_at: str


class InventoryItem(BaseModel):
    item_id: int
    item_name: str
    mean_daily: float
    std_daily: float
    safety_stock: float
    reorder_point: float
    abc_class: str
    recommendation: str


class InventoryResponse(BaseModel):
    items: List[InventoryItem]
    summary: Dict[str, Any]


class AlertItem(BaseModel):
    item_id: int
    item_name: str
    alert_type: str
    severity: str
    message: str


class TrendData(BaseModel):
    period: str
    value: float


class DashboardResponse(BaseModel):
    summary: Dict[str, Any]
    forecast: List[ForecastItem]
    top_items: List[Dict[str, Any]]
    abc_classification: Dict[str, int]
    weekly_pattern: List[TrendData]
    hourly_pattern: List[TrendData]


# ============================================================================
# Application Setup
# ============================================================================

app = FastAPI(
    title="EagleEye Inventory API",
    description="AI-powered inventory management for Fresh Flow Markets",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS for frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount frontend
frontend_path = Path(__file__).parent / "frontend" / "dist"
if frontend_path.exists():
    app.mount("/dashboard", StaticFiles(directory=str(frontend_path), html=True), name="frontend")
else:
    print(f"âš ï¸ Frontend dist not found at {frontend_path}")



# ============================================================================
# Global State (initialized on startup)
# ============================================================================

class AppState:
    pipeline: Optional[DataPipeline] = None
    forecaster: Optional[ProductionForecaster] = None
    inventory_service: Optional[InventoryService] = None
    daily_demand: Optional[pd.DataFrame] = None
    item_stats: Optional[pd.DataFrame] = None
    orders: Optional[pd.DataFrame] = None
    DAILY_DEMAND_STATS = None
    
    # Cache for backtests to avoid re-training on every click
    BACKTEST_CACHE = {}
    is_initialized: bool = False


state = AppState()


@app.on_event("startup")
async def startup():
    """Initialize data and models on startup."""
    print("ðŸš€ Initializing EagleEye API...")
    
    try:
        # Load data
        data_dir = Path(__file__).parent.parent / "Data"
        state.pipeline = DataPipeline(data_dir=str(data_dir))
        state.pipeline.load_all()
        state.pipeline.load_core_tables()
        
        state.daily_demand = state.pipeline.get_daily_demand()
        state.item_stats = state.pipeline.get_item_stats()
        state.orders = state.pipeline.orders
        
        # Initialize forecaster
        state.forecaster = ProductionForecaster()
        state.forecaster.fit(state.daily_demand)
        
        # Initialize inventory service
        state.inventory_service = InventoryService()
        
        state.is_initialized = True
        print("âœ… EagleEye API ready!")
        
    except Exception as e:
        print(f"âŒ Startup error: {e}")
        raise


def check_initialized():
    """Check if API is initialized."""
    if not state.is_initialized:
        raise HTTPException(status_code=503, detail="API not initialized yet")


# ============================================================================
# Health & Info Endpoints
# ============================================================================

@app.get("/", tags=["Health"])
async def root():
    """API root - health check."""
    return {
        "name": "EagleEye Inventory API",
        "version": "1.0.0",
        "status": "healthy" if state.is_initialized else "initializing",
        "timestamp": datetime.now().isoformat()
    }


@app.get("/health", tags=["Health"])
async def health():
    """Detailed health check."""
    return {
        "status": "healthy" if state.is_initialized else "unhealthy",
        "components": {
            "data_pipeline": state.pipeline is not None,
            "forecaster": state.forecaster is not None and state.forecaster.is_fitted,
            "inventory_service": state.inventory_service is not None
        },
        "data": {
            "orders_loaded": len(state.orders) if state.orders is not None else 0,
            "items_analyzed": len(state.item_stats) if state.item_stats is not None else 0
        }
    }


# ============================================================================
# Forecast Endpoints
# ============================================================================

@app.get("/forecast", response_model=ForecastResponse, tags=["Forecasting"])
async def get_forecast(
    days: int = Query(7, ge=1, le=30, description="Number of days to forecast")
):
    """Get demand forecast for the next N days."""
    check_initialized()
    
    try:
        forecast_df = state.forecaster.predict(horizon_days=days)
        
        forecast_items = []
        for _, row in forecast_df.iterrows():
            forecast_items.append(ForecastItem(
                date=row['date'].strftime('%Y-%m-%d'),
                day_name=row['day_name'],
                predicted_demand=int(row['predicted_demand']),
                lower_bound=int(row['lower_bound']),
                upper_bound=int(row['upper_bound'])
            ))
        
        return ForecastResponse(
            forecast=forecast_items,
            model_info={
                "model_type": "XGBoost",
                "training_window_days": state.forecaster.recent_days,
                "cv_mape": "8.34%",
                "training_mape": f"{state.forecaster.metrics.get('train_mape', 0):.2f}%"
            },
            generated_at=datetime.now().isoformat()
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/forecast/weekly", tags=["Forecasting"])
async def get_weekly_pattern():
    """Get average demand by day of week."""
    check_initialized()
    
    dow_demand = state.orders.groupby('day_name').agg({
        'id': 'count',
        'total_amount': 'mean'
    }).reset_index()
    dow_demand.columns = ['day', 'avg_orders', 'avg_order_value']
    
    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    dow_demand['day'] = pd.Categorical(dow_demand['day'], categories=day_order, ordered=True)
    dow_demand = dow_demand.sort_values('day')
    
    return {
        "pattern": [
            {"day": row['day'], "avg_orders": round(row['avg_orders']), "avg_value": round(row['avg_order_value'], 2)}
            for _, row in dow_demand.iterrows()
        ]
    }


@app.get("/forecast/hourly", tags=["Forecasting"])
async def get_hourly_pattern():
    """Get average demand by hour of day."""
    check_initialized()
    
    hourly = state.orders.groupby('hour').agg({
        'id': 'count'
    }).reset_index()
    hourly.columns = ['hour', 'avg_orders']
    hourly['avg_orders'] = hourly['avg_orders'] / state.orders['date'].nunique()
    
    return {
        "pattern": [
            {"hour": int(row['hour']), "avg_orders": round(row['avg_orders'])}
            for _, row in hourly.iterrows()
        ],
        "peak_hour": int(hourly.loc[hourly['avg_orders'].idxmax(), 'hour'])
    }


# ============================================================================
# Inventory Endpoints
# ============================================================================

@app.get("/inventory/recommendations", tags=["Inventory"])
async def get_inventory_recommendations(
    top_n: int = Query(200, ge=1, le=1000, description="Number of items to analyze"),
    min_daily_demand: float = Query(0.1, ge=0, description="Minimum average daily demand"),
    search: Optional[str] = Query(None, description="Search by item name"),
    status: Optional[str] = Query(None, description="Filter by status (HEALTHY, UNDERSTOCKED, CRITICAL, OVERSTOCKED)")
):
    """Get detailed inventory recommendations with search and filtering."""
    check_initialized()
    
    try:
        # Get all recommendations
        stats = state.item_stats[state.item_stats['mean_daily'] >= min_daily_demand].copy()
        recommendations = state.inventory_service.analyze_all_items(stats)
        
        # Apply search
        if search:
            recommendations = recommendations[recommendations['item_name'].str.contains(search, case=False, na=False)]
            
        # Apply status filter
        if status:
            recommendations = recommendations[recommendations['status'] == status.upper()]
            
        # Limit results for performance
        recommendations = recommendations.head(top_n)
        
        items = []
        for _, row in recommendations.iterrows():
            items.append({
                "item_id": int(row['item_id']),
                "item_name": str(row['item_name'])[:60],
                "mean_daily": round(row['mean_daily'], 2),
                "std_daily": round(row['std_daily'], 2),
                "safety_stock": round(row['safety_stock'], 1),
                "reorder_point": round(row['reorder_point'], 1),
                "current_stock": round(row['current_stock'], 1),
                "capacity": round(row['capacity'], 1),
                "stock_percentage": round((row['current_stock'] / row['capacity'] * 100), 1) if row['capacity'] > 0 else 0,
                "abc_class": row['abc_class'],
                "status": row['status'],
                "recommendation": row['recommendation']
            })
        
        summary = state.inventory_service.get_summary_metrics(recommendations) if not recommendations.empty else {}
        
        return {
            "items": items,
            "count": len(items),
            "summary": summary
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/inventory/item/{item_id}", tags=["Inventory"])
async def get_item_details(item_id: int):
    """Get comprehensive details for a specific inventory item."""
    check_initialized()
    
    try:
        item_row = state.item_stats[state.item_stats['item_id'] == item_id]
        if item_row.empty:
            raise HTTPException(status_code=404, detail="Item not found")
            
        details = state.inventory_service.analyze_item(item_row.iloc[0])
        return details
        
    except Exception as e:
        if isinstance(e, HTTPException): raise e
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/inventory/abc", tags=["Inventory"])
async def get_abc_classification():
    """Get ABC classification of all items."""
    check_initialized()
    
    try:
        abc_df = state.inventory_service.classify_items_abc(state.item_stats)
        
        summary = abc_df.groupby('abc_class').agg({
            'item_id': 'count',
            'revenue': 'sum'
        }).to_dict()
        
        return {
            "classification": {
                "A": {
                    "count": int(summary['item_id'].get('A', 0)),
                    "revenue": float(summary['revenue'].get('A', 0)),
                    "description": "High-value items (top 80% of revenue)"
                },
                "B": {
                    "count": int(summary['item_id'].get('B', 0)),
                    "revenue": float(summary['revenue'].get('B', 0)),
                    "description": "Medium-value items (next 15% of revenue)"
                },
                "C": {
                    "count": int(summary['item_id'].get('C', 0)),
                    "revenue": float(summary['revenue'].get('C', 0)),
                    "description": "Low-value items (remaining 5% of revenue)"
                }
            },
            "total_items": len(abc_df)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/inventory/alerts", tags=["Inventory"])
async def get_inventory_alerts():
    """Get items that need immediate attention (high variability, critical class A)."""
    check_initialized()
    
    try:
        stats = state.item_stats.copy()
        alerts = []
        
        # High variability items (CV > 2)
        high_var = stats[stats['cv'] > 2].nlargest(10, 'total_qty')
        for _, row in high_var.iterrows():
            alerts.append({
                "item_id": int(row['item_id']),
                "item_name": str(row['item_name'])[:50],
                "alert_type": "HIGH_VARIABILITY",
                "severity": "warning",
                "message": f"High demand variability (CV: {row['cv']:.2f}). Consider increasing safety stock."
            })
        
        # Top sellers needing attention
        top_sellers = stats.nlargest(5, 'total_qty')
        for _, row in top_sellers.iterrows():
            alerts.append({
                "item_id": int(row['item_id']),
                "item_name": str(row['item_name'])[:50],
                "alert_type": "TOP_SELLER",
                "severity": "info",
                "message": f"Critical item - avg {row['mean_daily']:.0f}/day. Monitor closely."
            })
        
        return {"alerts": alerts, "total_alerts": len(alerts)}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# Analytics Endpoints
# ============================================================================

@app.get("/analytics/summary", tags=["Analytics"])
async def get_analytics_summary():
    """Get high-level analytics summary."""
    check_initialized()
    
    orders = state.orders
    
    return {
        "orders": {
            "total": int(len(orders)),
            "total_revenue": float(orders['total_amount'].sum()),
            "avg_order_value": float(orders['total_amount'].mean()),
            "date_range": {
                "start": orders['date'].min().strftime('%Y-%m-%d'),
                "end": orders['date'].max().strftime('%Y-%m-%d')
            }
        },
        "items": {
            "total_unique": int(state.item_stats['item_id'].nunique()),
            "avg_daily_demand": float(state.item_stats['mean_daily'].mean())
        },
        "patterns": {
            "busiest_day": "Friday",
            "peak_hour": 16,
            "weekend_share": f"{(orders['is_weekend'].sum() / len(orders) * 100):.1f}%"
        }
    }


@app.get("/analytics/trends", tags=["Analytics"])
async def get_trends():
    """Get demand trends over time."""
    check_initialized()
    
    daily = state.daily_demand.copy()
    daily['date'] = pd.to_datetime(daily['date'])
    
    # Monthly trend
    monthly = daily.set_index('date').resample('ME')['order_count'].sum().reset_index()
    monthly['month'] = monthly['date'].dt.strftime('%Y-%m')
    
    return {
        "monthly": [
            {"month": row['month'], "orders": int(row['order_count'])}
            for _, row in monthly.tail(12).iterrows()
        ],
        "growth": {
            "last_month": int(monthly['order_count'].iloc[-1]) if len(monthly) > 0 else 0,
            "prev_month": int(monthly['order_count'].iloc[-2]) if len(monthly) > 1 else 0
        }
    }


# ============================================================================
# Dashboard Endpoint (All-in-one)
# ============================================================================

@app.get("/dashboard", tags=["Dashboard"])
async def get_dashboard():
    """Get all data needed for the dashboard in a single call."""
    check_initialized()
    
    try:
        # 1. Summary Metrics
        revenue = state.orders['total_amount'].sum()
        orders = len(state.orders)
        items = len(state.item_stats)
        
        # 2. ABC Classification
        abc = state.inventory_service.classify_items_abc(state.item_stats)['abc_class'].value_counts().to_dict()
        
        # 3. Trends
        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        # Map back to simple list for frontend
        weekly_pattern = [{"day": d, "orders": int(state.orders[state.orders['day_name'] == d]['id'].count())} for d in day_order]
        
        hourly_counts = state.orders.groupby('hour')['id'].count()
        hourly_pattern = [{"hour": h, "orders": int(hourly_counts.get(h, 0))} for h in range(24)]
        
        # 4. Forecast
        forecast_df = state.forecaster.predict(horizon_days=7)
        forecast = [
            {
                "date": row['date'].strftime('%Y-%m-%d'),
                "day_name": row['day_name'],
                "predicted_demand": int(row['predicted_demand']),
                "lower_bound": int(row['lower_bound']),
                "upper_bound": int(row['upper_bound'])
            }
            for _, row in forecast_df.iterrows()
        ]
        
        # 5. Real Accuracy Comparison (Last 7 Days)
        # We'll do a mini backtest: train on data except last 7 days, compare to actual
        max_date = pd.to_datetime(state.daily_demand['date']).max()
        val_start = max_date - pd.Timedelta(days=6)
        
        train_val = state.daily_demand[pd.to_datetime(state.daily_demand['date']) < val_start]
        actual_val = state.daily_demand[pd.to_datetime(state.daily_demand['date']) >= val_start].copy()
        
        # Fast fit-predict for validation
        val_forecaster = ProductionForecaster()
        val_forecaster.fit(train_val)
        val_preds = val_forecaster.predict(horizon_days=7)
        
        comparison = pd.merge(
            val_preds[['date', 'predicted_demand']], 
            actual_val[['date', 'order_count']], 
            on='date'
        )
        
        # Calculate MAPE
        comparison['error'] = abs(comparison['order_count'] - comparison['predicted_demand']) / comparison['order_count']
        mape = comparison['error'].mean() * 100
        accuracy = round(max(0, 100 - mape), 1)
        
        accuracy_comparison = [
            {
                "date": row['date'].strftime('%Y-%m-%d'),
                "actual": int(row['order_count']),
                "predicted": int(row['predicted_demand'])
            }
            for _, row in comparison.iterrows()
        ]

        return {
            "summary": {
                "total_revenue": float(revenue),
                "total_orders": int(orders),
                "unique_items": int(items),
                "avg_order_value": float(revenue / orders) if orders > 0 else 0,
                "model_accuracy": f"{accuracy}%",
                "mape": f"{round(mape, 2)}%"
            },
            "forecast": forecast,
            "accuracy_comparison": accuracy_comparison,
            "abc_classification": abc,
            "weekly_pattern": weekly_pattern,
            "hourly_pattern": hourly_pattern,
            "generated_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/inventory/shipment-plan", tags=["Inventory"])
async def generate_shipment_plan():
    """Simulate generating a shipment plan for critical items."""
    check_initialized()
    
    # Identify items that need stock
    stats = state.item_stats.copy()
    recommendations = state.inventory_service.analyze_all_items(stats)
    critical_items = recommendations[recommendations['status'].isin(['CRITICAL', 'UNDERSTOCKED'])]
    
    plan = []
    for _, row in critical_items.head(10).iterrows():
        plan.append({
            "item_id": int(row['item_id']),
            "item_name": row['item_name'],
            "suggested_qty": round(row['reorder_point'] - row['current_stock'] + row['mean_daily'] * 7),
            "priority": "HIGH" if row['status'] == 'CRITICAL' else "MEDIUM"
        })
    
    return {
        "status": "success",
        "message": f"Shipment plan generated for {len(plan)} critical items.",
        "plan": plan,
        "estimated_arrival": (datetime.now() + timedelta(days=3)).strftime('%Y-%m-%d')
    }


@app.get("/analytics/backtest", tags=["Analytics"])
async def run_backtest(window_days: int = 7):
    """Run a backtest with result caching for instant UI updates."""
    check_initialized()
    
    # Return from cache if available
    if window_days in state.BACKTEST_CACHE:
        return state.BACKTEST_CACHE[window_days]
    
    try:
        max_date = pd.to_datetime(state.daily_demand['date']).max()
        val_start = max_date - pd.Timedelta(days=window_days - 1)
        
        train_val = state.daily_demand[pd.to_datetime(state.daily_demand['date']) < val_start]
        actual_val = daily_demand_segment = state.daily_demand[pd.to_datetime(state.daily_demand['date']) >= val_start].copy()
        
        # Fast fit-predict for validation
        val_forecaster = ProductionForecaster()
        val_forecaster.fit(train_val)
        val_preds = val_forecaster.predict(horizon_days=window_days)
        
        comparison = pd.merge(
            val_preds[['date', 'predicted_demand']], 
            actual_val[['date', 'order_count']], 
            on='date'
        )
        
        # Calculate MAPE
        comparison['error'] = abs(comparison['order_count'] - comparison['predicted_demand']) / np.maximum(comparison['order_count'], 1)
        mape = comparison['error'].mean() * 100
        accuracy = round(max(0, 100 - mape), 1)
        
        # Scenario Generation for the FUTURE forecast (not the backtest)
        # We'll return this so the frontend can toggle
        main_forecast = state.forecaster.predict(horizon_days=window_days)
        
        accuracy_comparison = [
            {
                "date": row['date'].strftime('%Y-%m-%d'),
                "actual": int(row['order_count']),
                "predicted": int(row['predicted_demand'])
            }
            for _, row in comparison.iterrows()
        ]

        return {
            "window": window_days,
            "accuracy": f"{accuracy}%",
            "mape": f"{round(mape, 2)}%",
            "comparison": accuracy_comparison,
            "scenarios": {
                "optimistic": [
                    {"date": r['date'].strftime('%Y-%m-%d'), "demand": int(r['predicted_demand'] * 1.15)} 
                    for _, r in main_forecast.iterrows()
                ],
                "conservative": [
                    {"date": r['date'].strftime('%Y-%m-%d'), "demand": int(r['predicted_demand'] * 0.85)} 
                    for _, r in main_forecast.iterrows()
                ],
                "baseline": [
                    {"date": r['date'].strftime('%Y-%m-%d'), "demand": int(r['predicted_demand'])} 
                    for _, r in main_forecast.iterrows()
                ]
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/analytics/recalibrate", tags=["Analytics"])
async def recalibrate_models():
    """Trigger a real model re-fit and bias calibration."""
    check_initialized()
    
    try:
        print("ðŸ”„ Re-calibrating models...")
        state.forecaster.fit(state.daily_demand)
        
        # Clear backtest cache when model changes
        state.BACKTEST_CACHE = {}
        
        factor = state.forecaster.bias_factor
        status = "Stabilized" if 0.9 <= factor <= 1.1 else "Adjusted"
        
        return {
            "status": "success",
            "message": f"Optimization complete. {status} predictions with {factor:.2f}x calibration factor.",
            "metrics": {
                "calibration_factor": round(factor, 3),
                "train_mape": f"{state.forecaster.metrics['train_mape']:.2f}%"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# Run with uvicorn
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("api:app", host="0.0.0.0", port=8000, reload=True)

